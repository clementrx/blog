[
  {
    "objectID": "about-fr.html",
    "href": "about-fr.html",
    "title": "Clément Rieux",
    "section": "",
    "text": "English  Français  Español\n\n\n\nBonjour!\nJe m’appelle Clément, et je suis Data Scientist en France.\nJe suis un fan de R et je l’utilise quotidiennement.\nJ’ai un Master d’Economie de Toulouse School of Economis, et je travaille pour EDF en tant que Data Scientist."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Clément Rieux",
    "section": "",
    "text": "Nov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n See all"
  },
  {
    "objectID": "index.html#recent-posts-articles-récents",
    "href": "index.html#recent-posts-articles-récents",
    "title": "Clément Rieux",
    "section": "",
    "text": "Nov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n See all"
  },
  {
    "objectID": "index.html#posts-in-english",
    "href": "index.html#posts-in-english",
    "title": "Clément Rieux",
    "section": "Posts in English",
    "text": "Posts in English\n\n\n\n\n  \n\n\n\n\nCloseread Prize: Evolution of Javelin throw distances\n\n\nWill the javelin throw record be broken one day ?\n\n\n\n\n\n\n19 min\n\n\n\n\n\n\n  \n\n\n\n\nWeb scraping and tv show analysis\n\n\nGet and plot imdb data\n\n\n\n\nscraping\n\n\nplot\n\n\nhttr\n\n\nWeb Scraping\n\n\n \n\n\n\n\nMar 20, 2023\n\n\nClément Rieux\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\nFilter your data with Python\n\n\nSelection of rows or columns\n\n\n\n\npython\n\n\nfilter\n\n\n \n\n\n\n\nJan 1, 2023\n\n\nClément Rieux\n\n\n1 min\n\n\n\n\n\n\nNo matching items\n\n\n See all posts in English"
  },
  {
    "objectID": "index.html#articles-en-français",
    "href": "index.html#articles-en-français",
    "title": "Clément Rieux",
    "section": "Articles en Français",
    "text": "Articles en Français\n\n\n\n\n  \n\n\n\n\nMétriques pour la classification\n\n\nComparer et comprendre les métriques de classification en Python et R\n\n\n\n\npython\n\n\nclassification\n\n\nR\n\n\nmetriques\n\n\n \n\n\n\n\nNov 30, 2024\n\n\nClément Rieux\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nLes library à connaitre\n\n\nTop library R\n\n\n\n\nlibrary\n\n\npackage\n\n\n \n\n\n\n\nMar 21, 2023\n\n\nClément Rieux\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nUtiliser Chat GPT avec R\n\n\nLibrary (gptstudio)\n\n\n\n\ngpt\n\n\nchat GPT\n\n\naddins\n\n\n \n\n\n\n\nJan 1, 2023\n\n\nClément Rieux\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nFiltrer ses données avec Python\n\n\nSélection de lignes ou colonnes\n\n\n\n\npython\n\n\nfiltre\n\n\n \n\n\n\n\nJan 1, 2023\n\n\nClément Rieux\n\n\n1 min\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n\n Voir les articles en Français"
  },
  {
    "objectID": "index.html#artículos-en-español",
    "href": "index.html#artículos-en-español",
    "title": "Clément Rieux",
    "section": "Artículos en español",
    "text": "Artículos en español\n\n\n\n\n  \n\n\n\n\nMétricas para la clasificación\n\n\nComparar y comprender las métricas de clasificación en Python y R\n\n\n\n\npython\n\n\nclasificación\n\n\nR\n\n\nmétricas\n\n\n \n\n\n\n\nNov 30, 2024\n\n\nClément Rieux\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nLibrary para saber\n\n\nTop library R\n\n\n\n\nlibrary\n\n\npackage\n\n\n \n\n\n\n\nMar 21, 2023\n\n\nClément Rieux\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nFiltra tus datos con Python\n\n\nSelección de filas o columnas\n\n\n\n\npython\n\n\nFiltra\n\n\n \n\n\n\n\nJan 1, 2023\n\n\nClément Rieux\n\n\n1 min\n\n\n\n\n\n\nNo matching items\n\n\n Ver artículos en español"
  },
  {
    "objectID": "posts/2023-04-gpt/fr/index.html",
    "href": "posts/2023-04-gpt/fr/index.html",
    "title": "Utiliser Chat GPT avec R",
    "section": "",
    "text": "L’utilisation de l’intelligence artificielle (IA) pour diverses applications est en constante évolution ces dernières années. Avec l’émergence de la génération de langage naturel assistée par l’IA, il est maintenant possible de développer des systèmes qui peuvent comprendre et générer du texte de manière similaire à un humain. Dans cette optique, l’API Chat GPT développée par OpenAI est devenue une ressource précieuse pour les développeurs qui cherchent à incorporer cette technologie dans leurs projets.\nEn utilisant la library gptstudio, les développeurs peuvent facilement accéder à l’API Chat GPT et utiliser cette puissante technologie pour améliorer leurs applications. Dans cet article, nous allons explorer l’utilisation de la bibliothèque pour faire appel à l’API Chat GPT et discuter des avantages qu’elle peut apporter aux projets de développement de langage naturel."
  },
  {
    "objectID": "posts/2023-04-gpt/fr/index.html#introduction",
    "href": "posts/2023-04-gpt/fr/index.html#introduction",
    "title": "Utiliser Chat GPT avec R",
    "section": "",
    "text": "L’utilisation de l’intelligence artificielle (IA) pour diverses applications est en constante évolution ces dernières années. Avec l’émergence de la génération de langage naturel assistée par l’IA, il est maintenant possible de développer des systèmes qui peuvent comprendre et générer du texte de manière similaire à un humain. Dans cette optique, l’API Chat GPT développée par OpenAI est devenue une ressource précieuse pour les développeurs qui cherchent à incorporer cette technologie dans leurs projets.\nEn utilisant la library gptstudio, les développeurs peuvent facilement accéder à l’API Chat GPT et utiliser cette puissante technologie pour améliorer leurs applications. Dans cet article, nous allons explorer l’utilisation de la bibliothèque pour faire appel à l’API Chat GPT et discuter des avantages qu’elle peut apporter aux projets de développement de langage naturel."
  },
  {
    "objectID": "posts/2023-04-gpt/fr/index.html#installation",
    "href": "posts/2023-04-gpt/fr/index.html#installation",
    "title": "Utiliser Chat GPT avec R",
    "section": "Installation",
    "text": "Installation\n\ninstall.packages(\"gptstudio\")\n\nUne fois la library installée, nous avons besoin d’une API Key qu’on va récupérer sur notre compte OpenAI.\nCette API Key on peut la définir manuellement :\n\nSys.setenv(OPENAI_API_KEY = \"&lt;APIKEY&gt;\")\n\nOu l’ajouter dans notre fichier .Renvion en ouvrant l’éditeur :\n\nrequire(usethis)\nedit_r_environ(scope = \"project\")\n\nPuis en ajoutant notre Key :\n\nOPENAI_API_KEY= \"&lt;APIKEY&gt;\""
  },
  {
    "objectID": "posts/2023-04-gpt/fr/index.html#utilisation",
    "href": "posts/2023-04-gpt/fr/index.html#utilisation",
    "title": "Utiliser Chat GPT avec R",
    "section": "Utilisation",
    "text": "Utilisation\n\nlibrary(gptstudio)\n\nLes addins de cette library permettent plusieurs choses\n\nEchanger directement avec Chat GPT\nModifier du code directement en source selon ce que l’on souhaite\nVérifier la grammaire\nCommenter du code dans une sélection\n\nPetit bémol, le package est configuré en anglais, donc quand j’utilise l’addin des commentaires (très pratique), il va me commenter le code en Anglais. Comment faire si je veux l’avoir en Français ou dans une autre langue ?\nOn va donc éditer le package :\n\ntrace(addin_comment_code, edit = T)\n\nCela va nous ouvrir une popup :\n\n\n\n\n\nEt il nous suffit de remplacer la ligne de l’appel à l’API par un input en Français ou la langue désirée :\n\n\n\n\n\n\nA noter que le changement est temporaire (uniquement le temps de la session R). Pour changer définitivement la fonction il faut prendre la source du package, modifier le code et installer le package avec sa propre source, et/ou contribuer au développement du package.\n\nUne fois que tout est configuré, il ne reste plus qu’à coder (ou regarder la library coder pour nous)."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html",
    "href": "posts/2023-03-top-lib/fr/index.html",
    "title": "Les library à connaitre",
    "section": "",
    "text": "Lorsqu’il s’agit de travailler avec des données, R est l’un des langages de programmation les plus populaires et les plus puissants disponibles aujourd’hui. Avec sa vaste communauté de développeurs, R propose des milliers de packages pour aider à résoudre une grande variété de problèmes de traitement et d’analyse de données. Cependant, avec autant de packages disponibles, il peut être difficile de savoir par où commencer. Dans cet article, je vais vous présenter quelques-unes des bibliothèques R les plus populaires et les plus utiles pour vous aider à démarrer dans l’analyse de données avec R. Que vous soyez un débutant ou un utilisateur chevronné de R, vous devriez trouver quelque chose d’intéressant dans cette liste."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html#introduction",
    "href": "posts/2023-03-top-lib/fr/index.html#introduction",
    "title": "Les library à connaitre",
    "section": "",
    "text": "Lorsqu’il s’agit de travailler avec des données, R est l’un des langages de programmation les plus populaires et les plus puissants disponibles aujourd’hui. Avec sa vaste communauté de développeurs, R propose des milliers de packages pour aider à résoudre une grande variété de problèmes de traitement et d’analyse de données. Cependant, avec autant de packages disponibles, il peut être difficile de savoir par où commencer. Dans cet article, je vais vous présenter quelques-unes des bibliothèques R les plus populaires et les plus utiles pour vous aider à démarrer dans l’analyse de données avec R. Que vous soyez un débutant ou un utilisateur chevronné de R, vous devriez trouver quelque chose d’intéressant dans cette liste."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html#dplyr",
    "href": "posts/2023-03-top-lib/fr/index.html#dplyr",
    "title": "Les library à connaitre",
    "section": "dplyr",
    "text": "dplyr\n\n\n\n\n\ndplyr est LA library à connaitre absolument ! Elle va servir à la manipulation des données.\nIl faut retenir ces fonctions :\n\nmutate(): Ajouter une nouvelle colonne à un dataframe\nselect(): Sélectionner des colonnes\nfilter(): Filtrer les lignes du dataframe\nsummarise(): Faire des agrégations de données\narrange(): Ordonne les données\n\nEn connaissant ces fonctions, on connait 70% de la manipulation de données avec R."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html#stringr",
    "href": "posts/2023-03-top-lib/fr/index.html#stringr",
    "title": "Les library à connaitre",
    "section": "stringr",
    "text": "stringr\n\n\n\n\n\nstringr est la library à connaitre lorsque l’on veut manipuler du texte.\nIl faut retenir ces fonctions :\n\nstr_detect(): Détecte la présence d’un pattern.\nstr_count(): Compte le nombre de matchs.\nstr_subset(): Extrait le texte qui contient le pattern.\nstr_locate(): Donne la position d’un pattern.\nstr_extract(): Extrait le premier pattern trouvé.\nstr_replace(): Remplace le pattern par un nouveau.\nstr_split(): Sépare du texte en plusieurs parties."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html#ggplot2",
    "href": "posts/2023-03-top-lib/fr/index.html#ggplot2",
    "title": "Les library à connaitre",
    "section": "ggplot2",
    "text": "ggplot2\n\n\n\n\n\nggplot2 est une bibliothèque de graphiques largement utilisée avec le langage de programmation R. Elle offre une grande variété de fonctionnalités pour la création de graphiques de qualité professionnelle, qui peuvent être personnalisés selon les besoins de l’utilisateur.\nggplot2 est considéré comme l’une des bibliothèques de graphiques les plus puissantes et les plus flexibles disponibles dans R, cette library peut être utilisée pour créer des graphiques complexes tout en étant simple à utiliser, notamment la gestion de l’esthétique des graphiques, la création de graphiques en couches, la gestion des échelles et des axes, ainsi que la prise en charge des facettes et de la représentation graphique de données géographiques."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html#leaflet",
    "href": "posts/2023-03-top-lib/fr/index.html#leaflet",
    "title": "Les library à connaitre",
    "section": "leaflet",
    "text": "leaflet\n\n\n\n\n\nLeaflet est une bibliothèque JavaScript très populaire pour la création de cartes interactives. Utilisée conjointement avec le langage de programmation R, elle permet la création de cartes interactives complexes et personnalisées.\nLeaflet, prend en comte de nombreux types de données géographiques, la création de cartes multi-niveaux, la personnalisation des icônes et des infobulles, ainsi que l’intégration de couches personnalisées."
  },
  {
    "objectID": "posts/2023-03-top-lib/fr/index.html#lubridate",
    "href": "posts/2023-03-top-lib/fr/index.html#lubridate",
    "title": "Les library à connaitre",
    "section": "lubridate",
    "text": "lubridate\n\n\n\n\n\nLubridate est une bibliothèque R qui facilite la manipulation de données temporelles. Elle permet de gérer les dates et les heures avec une grande précision et une grande flexibilité. Les principales fonctionnalités de Lubridate, sont notamment la création de dates et d’heures, la gestion de différents formats de dates, la manipulation de fuseaux horaires, la conversion de dates et d’heures en différents formats de texte, ainsi que la gestion des durées."
  },
  {
    "objectID": "posts/2023-03-tv-show-plot/en/index.html",
    "href": "posts/2023-03-tv-show-plot/en/index.html",
    "title": "Web scraping and tv show analysis",
    "section": "",
    "text": "Hello !\nWeb scraping has revolutionized the way we collect data from the internet, providing us with valuable insights that were once difficult to obtain.\nIn recent years, web scraping has become increasingly popular in the entertainment industry, particularly when it comes to gathering data on TV show ratings and reviews.\nBy using web scraping tools, it is now possible to collect large amounts of data on a wide range of TV shows and analyze the data to identify patterns and trends. In this article, we will explore how web scraping can be used to collect TV show data, and how we can use this data to gain insights into the popularity and success of different shows.\nWe will also discuss how we can visualize the data using various tools and techniques to help us better understand the information we have gathered. Whether you are a TV enthusiast, a data analyst, or simply someone interested in learning more about the power of web scraping, this article will provide you with valuable insights and practical advice."
  },
  {
    "objectID": "posts/2023-03-tv-show-plot/en/index.html#introduction",
    "href": "posts/2023-03-tv-show-plot/en/index.html#introduction",
    "title": "Web scraping and tv show analysis",
    "section": "",
    "text": "Hello !\nWeb scraping has revolutionized the way we collect data from the internet, providing us with valuable insights that were once difficult to obtain.\nIn recent years, web scraping has become increasingly popular in the entertainment industry, particularly when it comes to gathering data on TV show ratings and reviews.\nBy using web scraping tools, it is now possible to collect large amounts of data on a wide range of TV shows and analyze the data to identify patterns and trends. In this article, we will explore how web scraping can be used to collect TV show data, and how we can use this data to gain insights into the popularity and success of different shows.\nWe will also discuss how we can visualize the data using various tools and techniques to help us better understand the information we have gathered. Whether you are a TV enthusiast, a data analyst, or simply someone interested in learning more about the power of web scraping, this article will provide you with valuable insights and practical advice."
  },
  {
    "objectID": "posts/2023-03-tv-show-plot/en/index.html#where-can-i-find-the-data",
    "href": "posts/2023-03-tv-show-plot/en/index.html#where-can-i-find-the-data",
    "title": "Web scraping and tv show analysis",
    "section": "Where can I find the data ?",
    "text": "Where can I find the data ?\nActually, it’s pretty easy to find rating of tv shows. imdb provides us all the data we need.\nFor example, if I’m looking data for Breaking Bad :\n\n\n\n\n\nI can get multiples informations :\n\nEpisode Name\nRating\nNumber of votes\nDate\nSypnosis\n\nIf I’m looking at the url : https://www.imdb.com/title/tt0903747/episodes?season=1, we have :\n\ntt0903747: Alias for the serie\nepisodes?season=1: Season number"
  },
  {
    "objectID": "posts/2023-03-tv-show-plot/en/index.html#how-can-i-get-the-data",
    "href": "posts/2023-03-tv-show-plot/en/index.html#how-can-i-get-the-data",
    "title": "Web scraping and tv show analysis",
    "section": "How can i get the data ?",
    "text": "How can i get the data ?\n\nLoad library\n\nlibrary(rvest) # manipulate HTML\nlibrary(stringr) # text manipulation\nlibrary(lubridate) # date manipulation\nlibrary(dplyr) # df manipulation\nlibrary(tidyr) # column manipulation\nlibrary(RColorBrewer) # color\nlibrary(ggplot2) # visualization\n\n\n\nInit the variables\n\n# Tv show title\nserie_title = 'Breaking Bad'\n\n# Seasons\ns = 5\n\n# Tv show code\ncode = 'tt0903747'\n\n# setup dataframe\ntable = data.frame()\n\n\n\nLoop to get informations for each season\nFor each season (webpage), we will get informations for each episode.\n\nGet the url\nDownload the .html page (we can also do it without downloading the page, but I prefer to retrieve the page locally\nExtract element, for this i use the extension SelectorGadget\nAppend in the dataframe\n\n\nfor(i in 1:s){\n  \n  url = paste0(\"https://www.imdb.com/title/\",code,\"/episodes?season=\",i)\n  \n  while(TRUE){\n    dl_file &lt;- try(download.file(as.character(url), destfile = \"temp.html\", quiet=TRUE),\n                   silent=TRUE)\n    if(!is(dl_file, 'try-error')) break\n  }\n  \n  html_page &lt;- read_html(\"temp.html\")\n  \n  saison = i\n  \n  episode &lt;- html_page %&gt;% \n    html_nodes(\"#episodes_content strong a\") %&gt;% \n    html_text() %&gt;% \n    str_replace_all(\"\\t|\\n|\", \"\")\n  \n  note &lt;- html_page %&gt;% \n    html_nodes(\".ipl-rating-star.small .ipl-rating-star__rating\") %&gt;% \n    html_text() %&gt;% \n    str_replace_all(\"\\t|\\n|\", \"\")\n  \n  vote &lt;- html_page %&gt;% \n    html_nodes(\".ipl-rating-star__total-votes\") %&gt;% \n    html_text() %&gt;% \n    str_replace_all(\"\\t|\\n|\", \"\")\n  \n  date &lt;- html_page %&gt;% \n    html_nodes(\".airdate\") %&gt;% \n    html_text() %&gt;% \n    str_replace_all(\"\\t|\\n|\", \"\") %&gt;% \n    dmy() %&gt;% \n    as.character()\n  \n  temp_table &lt;- as.data.frame(cbind(saison, episode, note, vote, date))\n  table &lt;- rbind(table,temp_table) \n  \n  file.remove('temp.html')\n  \n}\n\nPerfect ! Now we have a well table\n\n\n\n\n\nsaison\nepisode\nnote\nvote\ndate\n\n\n\n\n1\nPilot\n9.0\n(38,409)\n2010-10-09\n\n\n1\nCat’s in the Bag…\n8.6\n(28,007)\n2008-01-27\n\n\n1\n…And the Bag’s in the River\n8.7\n(27,115)\n2008-02-10\n\n\n1\nCancer Man\n8.2\n(26,142)\n2008-02-17\n\n\n1\nGray Matter\n8.3\n(25,676)\n2008-02-24\n\n\n1\nCrazy Handful of Nothin’\n9.3\n(30,176)\n2008-03-02"
  },
  {
    "objectID": "posts/2023-03-tv-show-plot/en/index.html#what-can-i-do-with-the-data",
    "href": "posts/2023-03-tv-show-plot/en/index.html#what-can-i-do-with-the-data",
    "title": "Web scraping and tv show analysis",
    "section": "What can I do with the data ?",
    "text": "What can I do with the data ?\nI use the code from z3tt for his TidyTuesday plot from The Office, which I find very cool.\nFirstly, we need to compute some informations that will be used to make a graph :\n\nEpisode number\nNote by season\nRating mean\n\n\ndf_avg &lt;-\n  table %&gt;% \n  group_by(saison) %&gt;% \n  mutate(episode = row_number(),\n         saison = as.numeric(saison),\n         note = as.numeric(note),\n         vote = gsub(',','',vote),\n         vote = as.numeric(gsub(\"[^\\\\d]+\", \"\", vote, perl=TRUE))\n  ) %&gt;% \n  ungroup() %&gt;% \n  arrange(saison, episode) %&gt;% \n  mutate(episode_id = row_number()) %&gt;% \n  group_by(saison) %&gt;% \n  mutate(\n    avg = mean(note),\n    episode_mod = episode_id + (9 * saison),\n    mid = mean(episode_mod)\n  ) %&gt;% \n  ungroup() %&gt;% \n  mutate(saison = factor(saison))\n\nSecondly, for each season summarize the rating :\n\ndf_lines &lt;-\n  df_avg %&gt;% \n  group_by(saison) %&gt;% \n  summarize(\n    start_x = min(episode_mod) -5,\n    end_x = max(episode_mod) + 5,\n    y = unique(avg)\n  ) %&gt;% \n  pivot_longer(\n    cols = c(start_x, end_x),\n    names_to = \"type\",\n    values_to = \"x\"\n  ) %&gt;% \n  mutate(\n    x_group = if_else(type == \"start_x\", x + .1, x - .1),\n    x_group = if_else(type == \"start_x\" & x == min(x), x_group - .1, x_group),\n    x_group = if_else(type == \"end_x\" & x == max(x), x_group + .1, x_group)\n  )\n\nThen plot :\n\nnb.cols &lt;- s\nmycolors &lt;- colorRampPalette(brewer.pal(8, \"Paired\"))(nb.cols)\n\ndf_avg %&gt;%\n  ggplot(aes(episode_mod, note)) +\n  geom_hline(\n    data = tibble(y = 7:11),\n    aes(yintercept = y),\n    color = \"grey82\",\n    size = .5\n  ) +\n  geom_segment(aes(\n    xend = episode_mod,\n    yend = avg,\n    color = saison,\n    color = after_scale(colorspace::lighten(color, .2))\n  )) +\n  geom_line(data = df_lines,\n            aes(\n              x_group,\n              y,\n              color = saison,\n              color = after_scale(colorspace::darken(color, .2))\n            ),\n            size = 2.5) +\n  geom_point(aes(size = vote,\n                 color = saison)) +\n  geom_label(\n    aes(\n      mid,\n      10.2,\n      label = glue::glue(\" Saison {saison} \"),\n      color = saison,\n      color = after_scale(colorspace::darken(color, .2))\n    ),\n    show.legend = FALSE,\n    fill = NA,\n    label.padding = unit(.2, \"lines\"),\n    label.r = unit(.25, \"lines\"),\n    label.size = .5\n  )  +\n  scale_x_continuous(expand = c(.015, .015)) +\n  scale_y_continuous(\n    expand = c(.03, .03),\n    limits = c(6.5, 10.5),\n    breaks = seq(6.5, 10, by = .5),\n    sec.axis = dup_axis(name = NULL)\n  ) +\n  scale_color_manual(values = mycolors, guide = \"none\") +\n  scale_size_binned(\n    name = \"Votes per episode\",\n    range = c(.3, 6),\n    labels = function(x)\n      format(x, big.mark = \" \", scientific = FALSE)\n  ) +\n  ggtitle(serie_title) +\n  labs(x = \"\", y = \"Rating\",\n       caption = \"Visualization by Clément Rieux\") +\n  guides(\n    size = guide_bins(\n      show.limits = T,\n      direction = \"horizontal\",\n      title.position = \"top\",\n      title.hjust = .5\n    )\n  ) +\n  theme(\n    legend.position = c(.2, .085),\n    legend.key.size = unit(1, 'cm'),\n    legend.key.width = unit(2, \"lines\"),\n    legend.text = element_text(\n      angle = 60,\n      vjust = 1,\n      hjust = 1\n    ),\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank()\n  )\n\n\n\n\nWe can also look at the evolution over time :\n\ndf_avg %&gt;% \n  mutate(date = as.Date(date)) %&gt;%  \n  ggplot(aes(x = date, y = note, color = note)) +\n  geom_point() +\n  scale_colour_gradient(low = \"#E84D23\", high = \"#3CDE0B\", na.value = NA) + \n  scale_x_date(date_breaks = \"3 month\", date_labels = \"%b-%Y\") + \n  theme_classic() + \n  theme(axis.text.x = element_text(angle = 70, hjust = 1)) \n\n\n\n\nNow you are able to retrieve data from imdb and do analysis yourself !\nIf you want to see all the code and examples (Stranger Things, Peaky Bliders, The Simpsons…), you can find it on my github."
  },
  {
    "objectID": "posts/2023-04-python-filter/es/index.html",
    "href": "posts/2023-04-python-filter/es/index.html",
    "title": "Filtra tus datos con Python",
    "section": "",
    "text": "El objetivo de este tutorial es comprender rápidamente cómo filtrar datos con Python."
  },
  {
    "objectID": "posts/2023-04-python-filter/es/index.html#cómo-filtrar-datos-en-python",
    "href": "posts/2023-04-python-filter/es/index.html#cómo-filtrar-datos-en-python",
    "title": "Filtra tus datos con Python",
    "section": "",
    "text": "El objetivo de este tutorial es comprender rápidamente cómo filtrar datos con Python."
  },
  {
    "objectID": "posts/2023-04-python-filter/es/index.html#datos",
    "href": "posts/2023-04-python-filter/es/index.html#datos",
    "title": "Filtra tus datos con Python",
    "section": "Datos",
    "text": "Datos\n\nimport pandas as pd\n\nnoms = ['Jean', 'Lucie', 'Pierre', 'Marie', 'Antoine', 'Sophie']\nages = [25, 30, 20, 40, 35, 28]\nvilles = ['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Bordeaux', 'Nantes']\ndf = pd.DataFrame({'Nom': noms, 'Age': ages, 'Ville': villes})\n\nprint(df)\n\n       Nom  Age      Ville\n0     Jean   25      Paris\n1    Lucie   30       Lyon\n2   Pierre   20  Marseille\n3    Marie   40   Toulouse\n4  Antoine   35   Bordeaux\n5   Sophie   28     Nantes"
  },
  {
    "objectID": "posts/2023-04-python-filter/es/index.html#filtros",
    "href": "posts/2023-04-python-filter/es/index.html#filtros",
    "title": "Filtra tus datos con Python",
    "section": "Filtros",
    "text": "Filtros\nFiltrar filas para personas menores de 30 años :\n\ndf_30 = df[df['Age'] &lt; 30]\nprint(df_30)\n\n      Nom  Age      Ville\n0    Jean   25      Paris\n2  Pierre   20  Marseille\n5  Sophie   28     Nantes\n\n\nSelección de líneas para menores de 30 años que viven en Nantes o París :\n\ndf_filtre = df[(df['Age'] &lt; 30) & ((df['Ville'] == 'Nantes') | (df['Ville'] == 'Paris'))]\n\nprint(df_filtre)\n\n      Nom  Age   Ville\n0    Jean   25   Paris\n5  Sophie   28  Nantes\n\n\nFiltrar columnas solo por nombres y ciudades :\n\ndf_name_city = df[['Nom', 'Ville']]\nprint(df_name_city)\n\n       Nom      Ville\n0     Jean      Paris\n1    Lucie       Lyon\n2   Pierre  Marseille\n3    Marie   Toulouse\n4  Antoine   Bordeaux\n5   Sophie     Nantes\n\n\nRecuperación del nombre y la edad de personas menores de 30 años que viven en Nantes o París :\n\nfiltre = (df['Age'] &lt; 30) & ((df['Ville'] == 'Nantes') | (df['Ville'] == 'Paris'))\ndf_filtre = df.loc[filtre, ['Nom', 'Age']]\n\nprint(df_filtre)\n\n      Nom  Age\n0    Jean   25\n5  Sophie   28"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nCloseread Prize: Evolution of Javelin throw distances\n\n\nWill the javelin throw record be broken one day ?\n\n\n19 min\n\n\n\n\n\n\n\n\n\n\n\n\n\nMétricas para la clasificación\n\n\nComparar y comprender las métricas de clasificación en Python y R\n\n\n7 min\n\n\n\npython\n\n\nclasificación\n\n\nR\n\n\nmétricas\n\n\n\n\nNov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMétriques pour la classification\n\n\nComparer et comprendre les métriques de classification en Python et R\n\n\n7 min\n\n\n\npython\n\n\nclassification\n\n\nR\n\n\nmetriques\n\n\n\n\nNov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary para saber\n\n\nTop library R\n\n\n3 min\n\n\n\nlibrary\n\n\npackage\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes library à connaitre\n\n\nTop library R\n\n\n3 min\n\n\n\nlibrary\n\n\npackage\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping and tv show analysis\n\n\nGet and plot imdb data\n\n\n8 min\n\n\n\nscraping\n\n\nplot\n\n\nhttr\n\n\nWeb Scraping\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtiliser Chat GPT avec R\n\n\nLibrary (gptstudio)\n\n\n2 min\n\n\n\ngpt\n\n\nchat GPT\n\n\naddins\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter your data with Python\n\n\nSelection of rows or columns\n\n\n1 min\n\n\n\npython\n\n\nfilter\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiltra tus datos con Python\n\n\nSelección de filas o columnas\n\n\n1 min\n\n\n\npython\n\n\nFiltra\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiltrer ses données avec Python\n\n\nSélection de lignes ou colonnes\n\n\n1 min\n\n\n\npython\n\n\nfiltre\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/en.html",
    "href": "posts/en.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nCloseread Prize: Evolution of Javelin throw distances\n\n\nWill the javelin throw record be broken one day ?\n\n\n19 min\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping and tv show analysis\n\n\nGet and plot imdb data\n\n\n8 min\n\n\n\nscraping\n\n\nplot\n\n\nhttr\n\n\nWeb Scraping\n\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter your data with Python\n\n\nSelection of rows or columns\n\n\n1 min\n\n\n\npython\n\n\nfilter\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/fr.html",
    "href": "posts/fr.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nMétriques pour la classification\n\n\nComparer et comprendre les métriques de classification en Python et R\n\n\n7 min\n\n\n\npython\n\n\nclassification\n\n\nR\n\n\nmetriques\n\n\n\n\nNov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes library à connaitre\n\n\nTop library R\n\n\n3 min\n\n\n\nlibrary\n\n\npackage\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUtiliser Chat GPT avec R\n\n\nLibrary (gptstudio)\n\n\n2 min\n\n\n\ngpt\n\n\nchat GPT\n\n\naddins\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiltrer ses données avec Python\n\n\nSélection de lignes ou colonnes\n\n\n1 min\n\n\n\npython\n\n\nfiltre\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-04-python-filter/fr/index.html",
    "href": "posts/2023-04-python-filter/fr/index.html",
    "title": "Filtrer ses données avec Python",
    "section": "",
    "text": "Le but de ce tutoriel est de comprendre rapidement comment filtrer des données avec Python."
  },
  {
    "objectID": "posts/2023-04-python-filter/fr/index.html#comment-filtrer-ses-données-en-python",
    "href": "posts/2023-04-python-filter/fr/index.html#comment-filtrer-ses-données-en-python",
    "title": "Filtrer ses données avec Python",
    "section": "",
    "text": "Le but de ce tutoriel est de comprendre rapidement comment filtrer des données avec Python."
  },
  {
    "objectID": "posts/2023-04-python-filter/fr/index.html#données",
    "href": "posts/2023-04-python-filter/fr/index.html#données",
    "title": "Filtrer ses données avec Python",
    "section": "Données",
    "text": "Données\n\nimport pandas as pd\n\nnoms = ['Jean', 'Lucie', 'Pierre', 'Marie', 'Antoine', 'Sophie']\nages = [25, 30, 20, 40, 35, 28]\nvilles = ['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Bordeaux', 'Nantes']\ndf = pd.DataFrame({'Nom': noms, 'Age': ages, 'Ville': villes})\n\nprint(df)\n\n       Nom  Age      Ville\n0     Jean   25      Paris\n1    Lucie   30       Lyon\n2   Pierre   20  Marseille\n3    Marie   40   Toulouse\n4  Antoine   35   Bordeaux\n5   Sophie   28     Nantes"
  },
  {
    "objectID": "posts/2023-04-python-filter/fr/index.html#filtres",
    "href": "posts/2023-04-python-filter/fr/index.html#filtres",
    "title": "Filtrer ses données avec Python",
    "section": "Filtres",
    "text": "Filtres\nFiltrer les lignes pour les personnes âgées de moins de 30 ans :\n\ndf_30 = df[df['Age'] &lt; 30]\nprint(df_30)\n\n      Nom  Age      Ville\n0    Jean   25      Paris\n2  Pierre   20  Marseille\n5  Sophie   28     Nantes\n\n\nSélection des lignes pour les personnes de moins de 30 ans habitant à Nantes ou Paris :\n\ndf_filtre = df[(df['Age'] &lt; 30) & ((df['Ville'] == 'Nantes') | (df['Ville'] == 'Paris'))]\n\nprint(df_filtre)\n\n      Nom  Age   Ville\n0    Jean   25   Paris\n5  Sophie   28  Nantes\n\n\nFiltrer les colonnes pour les noms et les villes uniquement :\n\ndf_name_city = df[['Nom', 'Ville']]\nprint(df_name_city)\n\n       Nom      Ville\n0     Jean      Paris\n1    Lucie       Lyon\n2   Pierre  Marseille\n3    Marie   Toulouse\n4  Antoine   Bordeaux\n5   Sophie     Nantes\n\n\nRécupération du nom et de l’âge des personnes de moins de 30 ans qui habitent à Nantes ou Paris :\n\nfiltre = (df['Age'] &lt; 30) & ((df['Ville'] == 'Nantes') | (df['Ville'] == 'Paris'))\ndf_filtre = df.loc[filtre, ['Nom', 'Age']]\n\nprint(df_filtre)\n\n      Nom  Age\n0    Jean   25\n5  Sophie   28"
  },
  {
    "objectID": "posts/2023-04-python-filter/en/index.html",
    "href": "posts/2023-04-python-filter/en/index.html",
    "title": "Filter your data with Python",
    "section": "",
    "text": "The goal of this tutorial is to quickly understand how to filter data with Python."
  },
  {
    "objectID": "posts/2023-04-python-filter/en/index.html#how-to-filter-data-in-python",
    "href": "posts/2023-04-python-filter/en/index.html#how-to-filter-data-in-python",
    "title": "Filter your data with Python",
    "section": "",
    "text": "The goal of this tutorial is to quickly understand how to filter data with Python."
  },
  {
    "objectID": "posts/2023-04-python-filter/en/index.html#data",
    "href": "posts/2023-04-python-filter/en/index.html#data",
    "title": "Filter your data with Python",
    "section": "Data",
    "text": "Data\n\nimport pandas as pd\n\nnoms = ['Jean', 'Lucie', 'Pierre', 'Marie', 'Antoine', 'Sophie']\nages = [25, 30, 20, 40, 35, 28]\nvilles = ['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Bordeaux', 'Nantes']\ndf = pd.DataFrame({'Nom': noms, 'Age': ages, 'Ville': villes})\n\nprint(df)\n\n       Nom  Age      Ville\n0     Jean   25      Paris\n1    Lucie   30       Lyon\n2   Pierre   20  Marseille\n3    Marie   40   Toulouse\n4  Antoine   35   Bordeaux\n5   Sophie   28     Nantes"
  },
  {
    "objectID": "posts/2023-04-python-filter/en/index.html#filters",
    "href": "posts/2023-04-python-filter/en/index.html#filters",
    "title": "Filter your data with Python",
    "section": "Filters",
    "text": "Filters\nFilter rows for people under 30 :\n\ndf_30 = df[df['Age'] &lt; 30]\nprint(df_30)\n\n      Nom  Age      Ville\n0    Jean   25      Paris\n2  Pierre   20  Marseille\n5  Sophie   28     Nantes\n\n\nSelection of lines for people under 30 living in Nantes or Paris :\n\ndf_filtre = df[(df['Age'] &lt; 30) & ((df['Ville'] == 'Nantes') | (df['Ville'] == 'Paris'))]\n\nprint(df_filtre)\n\n      Nom  Age   Ville\n0    Jean   25   Paris\n5  Sophie   28  Nantes\n\n\nFilter columns for names and cities only :\n\ndf_name_city = df[['Nom', 'Ville']]\nprint(df_name_city)\n\n       Nom      Ville\n0     Jean      Paris\n1    Lucie       Lyon\n2   Pierre  Marseille\n3    Marie   Toulouse\n4  Antoine   Bordeaux\n5   Sophie     Nantes\n\n\nGet the name and age of people under 30 who live in Nantes or Paris:\n\nfiltre = (df['Age'] &lt; 30) & ((df['Ville'] == 'Nantes') | (df['Ville'] == 'Paris'))\ndf_filtre = df.loc[filtre, ['Nom', 'Age']]\n\nprint(df_filtre)\n\n      Nom  Age\n0    Jean   25\n5  Sophie   28"
  },
  {
    "objectID": "posts/es.html",
    "href": "posts/es.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nMétricas para la clasificación\n\n\nComparar y comprender las métricas de clasificación en Python y R\n\n\n7 min\n\n\n\npython\n\n\nclasificación\n\n\nR\n\n\nmétricas\n\n\n\n\nNov 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary para saber\n\n\nTop library R\n\n\n3 min\n\n\n\nlibrary\n\n\npackage\n\n\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFiltra tus datos con Python\n\n\nSelección de filas o columnas\n\n\n1 min\n\n\n\npython\n\n\nFiltra\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html",
    "href": "posts/2023-03-top-lib/es/index.html",
    "title": "Library para saber",
    "section": "",
    "text": "Cuando se trata de trabajar con datos, R es uno de los lenguajes de programación más populares y poderosos disponibles en la actualidad. Con su gran comunidad de desarrolladores, R ofrece miles de paquetes para ayudar a resolver una amplia variedad de problemas de procesamiento y análisis de datos. Sin embargo, con tantos paquetes disponibles, puede ser difícil saber por dónde empezar. En este artículo, le presentaré algunas de las library de R más populares y útiles para ayudarlo a iniciarse en el análisis de datos con R. Ya sea que sea un principiante o un usuario experimentado de R, debería encontrar algo interesante en esta lista."
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html#introducción",
    "href": "posts/2023-03-top-lib/es/index.html#introducción",
    "title": "Library para saber",
    "section": "",
    "text": "Cuando se trata de trabajar con datos, R es uno de los lenguajes de programación más populares y poderosos disponibles en la actualidad. Con su gran comunidad de desarrolladores, R ofrece miles de paquetes para ayudar a resolver una amplia variedad de problemas de procesamiento y análisis de datos. Sin embargo, con tantos paquetes disponibles, puede ser difícil saber por dónde empezar. En este artículo, le presentaré algunas de las library de R más populares y útiles para ayudarlo a iniciarse en el análisis de datos con R. Ya sea que sea un principiante o un usuario experimentado de R, debería encontrar algo interesante en esta lista."
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html#dplyr",
    "href": "posts/2023-03-top-lib/es/index.html#dplyr",
    "title": "Library para saber",
    "section": "dplyr",
    "text": "dplyr\n\n\n\n\n\ndplyr es LA library que absolutamente necesita saber! Se utilizará para la manipulación de datos.\nEstas funciones deben mantenerse:\n\nmutate(): Agregar una nueva columna a un marco de datos\nselect(): Seleccionar columnas\nfilter(): Filtrar filas de datos\nsummarise(): Hacer agregaciones de datos\narrange(): Ordenar los datos\n\nConociendo estas funciones conocemos el 70% de la manipulación de datos con R."
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html#stringr",
    "href": "posts/2023-03-top-lib/es/index.html#stringr",
    "title": "Library para saber",
    "section": "stringr",
    "text": "stringr\n\n\n\n\n\nstringr es la library para saber cuándo se quiere manipular el texto.\nEstas funciones deben mantenerse :\n\nstr_detect(): Detecta la presencia de un patrón.\nstr_count(): Cuente el número de coincidencias.\nstr_subset(): Extrae el texto que contiene el patrón.\nstr_locate(): Da la posición de un patrón.\nstr_extract(): Extrae el primer patrón encontrado.\nstr_replace(): Reemplaza el patrón por uno nuevo.\nstr_split(): Divide el texto en varias partes."
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html#ggplot2",
    "href": "posts/2023-03-top-lib/es/index.html#ggplot2",
    "title": "Library para saber",
    "section": "ggplot2",
    "text": "ggplot2\n\n\n\n\n\nggplot2 es una library de gráficos ampliamente utilizada con el lenguaje de programación R. Ofrece una amplia variedad de funciones para crear gráficos de aspecto profesional, que se pueden personalizar según las necesidades del usuario.\nggplot2 se considera una de las library de gráficos más poderosas y flexibles disponibles en R, esta library se puede usar para crear gráficos complejos y, al mismo tiempo, es fácil de usar, incluida la gestión de la estética del gráfico, la creación de gráficos en capas, la gestión de escalas y ejes, así como soporte para facetas y representación gráfica de datos geográficos."
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html#leaflet",
    "href": "posts/2023-03-top-lib/es/index.html#leaflet",
    "title": "Library para saber",
    "section": "leaflet",
    "text": "leaflet\n\n\n\n\n\nLeaflet es una library de JavaScript muy popular para crear mapas interactivos. Usado en conjunto con el lenguaje de programación R, permite la creación de mapas interactivos complejos y personalizados.\nLeaflet, tiene en cuenta muchos tipos de datos geográficos, la creación de mapas de varios niveles, la personalización de iconos e información sobre herramientas, así como la integración de capas personalizadas."
  },
  {
    "objectID": "posts/2023-03-top-lib/es/index.html#lubridate",
    "href": "posts/2023-03-top-lib/es/index.html#lubridate",
    "title": "Library para saber",
    "section": "lubridate",
    "text": "lubridate\n\n\n\n\n\nLubridate es una library de R que facilita la manipulación de datos temporales. Te permite gestionar fechas y horas con gran precisión y gran flexibilidad. Las características principales de Lubridate incluyen la creación de fechas y horas, la gestión de diferentes formatos de fecha, la manipulación de zonas horarias, la conversión de fechas y horas a diferentes formatos de texto y la gestión de duraciones."
  },
  {
    "objectID": "about-es.html",
    "href": "about-es.html",
    "title": "Clément Rieux",
    "section": "",
    "text": "English  Français  Español\n\n\n\n¡Buenos dias!\nMi nombre es Clément y soy científico de datos en Francia.\nSoy fanático de R y lo uso a diario.\nTengo una maestría en economía de Toulouse School of Economis, y trabajo para EDF como cientifico de datos."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Clément Rieux",
    "section": "",
    "text": "English  Français  Español\n\n\n\nHi!\nMy name is Clément, and I am Data Scientist from France.\nI’m a fan of R and use it daily.\nI have a master’s degree in economics from the Toulouse School of Economis, and I’m working at EDF as Data Scientist."
  },
  {
    "objectID": "posts/2024-11-metrics-classification/fr/index.html",
    "href": "posts/2024-11-metrics-classification/fr/index.html",
    "title": "Métriques pour la classification",
    "section": "",
    "text": "Nous cherchons à identifier les résultats d’un modèle qui cherche à différencier des prédictions de chiens et de chats. Pour évaluer leur performance, des métriques adaptées permettent de mesurer à quel point un modèle est précis, fiable et équilibré dans ses prédictions.\n\nPythonR\n\n\n\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 100\ndata = pd.DataFrame({\n    'true': ['chien'] * 50 + ['chat'] * 50,\n    'probs': np.concatenate([\n        np.random.uniform(0.5, 1, 50),  \n        np.random.uniform(0, 0.5, 50)   \n    ])\n})\n\ndata['pred'] = data['probs'].apply(lambda x: 'chien' if x &gt; 0.5 else 'chat')\n\nindices_erreurs = np.random.choice(n, 15, replace=False)\ndata.loc[indices_erreurs, 'probs'] = 1 - data.loc[indices_erreurs, 'probs']\ndata.loc[indices_erreurs, 'pred'] = data.loc[indices_erreurs, 'pred'].map({'chien': 'chat', 'chat': 'chien'})\n\n\n\n\nset.seed(123)\n\nn &lt;- 100\ndata &lt;- data.frame(\n  true = factor(c(rep(\"chien\", 50), rep(\"chat\", 50))),   \n  probs = c(runif(50, 0.5, 1), runif(50, 0, 0.5))        \n)\n\ndata$pred &lt;- factor(ifelse(data$probs &gt; 0.5, \"chien\", \"chat\"))\n\nindices_erreurs &lt;- sample(1:n, 15)   \ndata$probs[indices_erreurs] &lt;- 1 - data$probs[indices_erreurs]  \ndata$pred[indices_erreurs] &lt;- ifelse(data$pred[indices_erreurs] == \"chien\", \"chat\", \"chien\")"
  },
  {
    "objectID": "posts/2024-11-metrics-classification/fr/index.html#exemple-de-données",
    "href": "posts/2024-11-metrics-classification/fr/index.html#exemple-de-données",
    "title": "Métriques pour la classification",
    "section": "",
    "text": "Nous cherchons à identifier les résultats d’un modèle qui cherche à différencier des prédictions de chiens et de chats. Pour évaluer leur performance, des métriques adaptées permettent de mesurer à quel point un modèle est précis, fiable et équilibré dans ses prédictions.\n\nPythonR\n\n\n\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 100\ndata = pd.DataFrame({\n    'true': ['chien'] * 50 + ['chat'] * 50,\n    'probs': np.concatenate([\n        np.random.uniform(0.5, 1, 50),  \n        np.random.uniform(0, 0.5, 50)   \n    ])\n})\n\ndata['pred'] = data['probs'].apply(lambda x: 'chien' if x &gt; 0.5 else 'chat')\n\nindices_erreurs = np.random.choice(n, 15, replace=False)\ndata.loc[indices_erreurs, 'probs'] = 1 - data.loc[indices_erreurs, 'probs']\ndata.loc[indices_erreurs, 'pred'] = data.loc[indices_erreurs, 'pred'].map({'chien': 'chat', 'chat': 'chien'})\n\n\n\n\nset.seed(123)\n\nn &lt;- 100\ndata &lt;- data.frame(\n  true = factor(c(rep(\"chien\", 50), rep(\"chat\", 50))),   \n  probs = c(runif(50, 0.5, 1), runif(50, 0, 0.5))        \n)\n\ndata$pred &lt;- factor(ifelse(data$probs &gt; 0.5, \"chien\", \"chat\"))\n\nindices_erreurs &lt;- sample(1:n, 15)   \ndata$probs[indices_erreurs] &lt;- 1 - data$probs[indices_erreurs]  \ndata$pred[indices_erreurs] &lt;- ifelse(data$pred[indices_erreurs] == \"chien\", \"chat\", \"chien\")"
  },
  {
    "objectID": "posts/2024-11-metrics-classification/fr/index.html#metriques",
    "href": "posts/2024-11-metrics-classification/fr/index.html#metriques",
    "title": "Métriques pour la classification",
    "section": "Metriques",
    "text": "Metriques\n\nMatrice de confusion\nLa matrice de confusion est une représentation en tableau des prédictions correctes et incorrectes :\n\\[\n\\begin{bmatrix}\nTP & FP \\\\\nFN & TN\n\\end{bmatrix}\n\\]\n\nTP (True Positives) : Nombre de prédictions correctes pour la classe positive.\nFP (False Positives) : Nombre de prédictions incorrectes pour la classe positive.\nFN (False Negatives) : Nombre de prédictions incorrectes pour la classe négative.\nTN (True Negatives) : Nombre de prédictions correctes pour la classe négative.\n\n\nPythonR\n\n\n\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nconf_matrix = confusion_matrix(data['true'], data['pred'])\nprint(\"Matrice de confusion Python:\")\n\nMatrice de confusion Python:\n\nprint(conf_matrix)\n\n[[42  8]\n [ 7 43]]\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, \n            annot=True, \n            fmt='d',\n            xticklabels=['chat', 'chien'],\n            yticklabels=['chat', 'chien'])\nplt.title('Matrice de confusion (Python)')\nplt.xlabel('Valeur réelle')\nplt.ylabel('Prédiction')\nplt.show()\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\nprint(\"Matrice de confusion R:\")\n\n[1] \"Matrice de confusion R:\"\n\ntable(Prédit = data$pred, Réel = data$true)\n\n       Réel\nPrédit chat chien\n  chat    44     9\n  chien    6    41\n\nconf_matrix_r &lt;- as.data.frame(table(data$pred, data$true))\nnames(conf_matrix_r) &lt;- c(\"Prediction\", \"Real\", \"Count\")\n\nggplot(conf_matrix_r, \n       aes(x = Real, y = Prediction, fill = Count)) +\n  geom_tile() +\n  geom_text(aes(label = Count)) +\n  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n  theme_minimal() +\n  labs(title = \"Matrice de confusion (R)\")\n\n\n\n\n\n\n\n\n\nAccuracy\nL’Accuracy mesure la proportion de prédictions correctes parmi l’ensemble des prédictions.\n\\[\n\\text{Accuracy} = \\frac{\\text{Vrai Positifs} + \\text{Vrai Négatifs}}{\\text{Total}}\n\\]\n\nAvantages : Facile à comprendre et à interpréter. Représente bien la performance globale d’un modèle lorsque les classes sont équilibrées.\nInconvénients : Ne prend pas en compte le déséquilibre des classes. Un modèle peut avoir une haute accuracy même s’il classe mal les classes minoritaires.\n\n\nPythonR\n\n\n\nfrom sklearn.metrics import  accuracy_score\nacc_sklearn = accuracy_score(data['true'], data['pred'])\nprint(f\"Accuracy (sklearn): {acc_sklearn:.3f}\")\n\nAccuracy (sklearn): 0.850\n\n\n\n\n\nacc_simple &lt;- mean(data$pred == data$true)\nprint(paste(\"Accuracy (simple):\", round(acc_simple, 3)))\n\n[1] \"Accuracy (simple): 0.85\"\n\n\n\n\n\n\n\nPrécision\nLa précision est la proportion des prédictions positives correctes parmi toutes les prédictions positives.\n\nAvantages : Utile lorsque l’on veut minimiser les faux positifs. Par exemple, dans des scénarios où une fausse alerte coûte cher (par exemple, détection de fraude).\nInconvénients : Ne prend pas en compte les faux négatifs, ce qui peut être problématique dans certains cas, par exemple, lorsque l’on souhaite éviter les faux négatifs.\n\n\\[\n\\text{Précision} = \\frac{\\text{Vrai Positifs}}{\\text{Vrai Positifs} + \\text{Faux Positifs}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import  precision_score\n\nprecision_per_class = precision_score(\n    data['true'], \n    data['pred'], \n    average=None,\n    labels=['chat', 'chien']\n)\nprint(\"Précision par classe (sklearn):\")\n\nPrécision par classe (sklearn):\n\nprint(f\"Chat: {precision_per_class[0]:.3f}\")\n\nChat: 0.857\n\nprint(f\"Chien: {precision_per_class[1]:.3f}\")\n\nChien: 0.843\n\n# Précision moyenne\nprecision_avg = precision_score(\n    data['true'], \n    data['pred'], \n    average='macro'\n)\nprint(f\"Précision moyenne: {precision_avg:.3f}\")\n\nPrécision moyenne: 0.850\n\n\n\n\n\nconf_matrix &lt;- table(Prédit = data$pred, Réel = data$true)\nprecision_chat &lt;- conf_matrix[\"chat\",\"chat\"] / sum(conf_matrix[,\"chat\"])\nprecision_chien &lt;- conf_matrix[\"chien\",\"chien\"] / sum(conf_matrix[,\"chien\"])\n\nprint(\"\\nPrécision par classe (manuel):\")\n\n[1] \"\\nPrécision par classe (manuel):\"\n\nprint(paste(\"Chat:\", round(precision_chat, 3)))\n\n[1] \"Chat: 0.88\"\n\nprint(paste(\"Chien:\", round(precision_chien, 3)))\n\n[1] \"Chien: 0.82\"\n\nprecision_moy &lt;- mean(c(precision_chat, precision_chien))\nprint(paste(\"Précision moyenne:\", round(precision_moy, 3)))\n\n[1] \"Précision moyenne: 0.85\"\n\n\n\n\n\n\n\nRecall\nLe Recall mesure la proportion des vrais positifs détectés parmi tous les réels positifs. Il est particulièrement important lorsqu’on veut minimiser les faux négatifs.\n\nAvantages : Utile dans des contextes où il est crucial de capturer autant de cas positifs que possible (par exemple, dans les tests médicaux).\nInconvénients : Ignore les faux positifs, ce qui peut mener à une hausse des faux positifs dans certains cas.\n\n\\[\n\\text{Recall} = \\frac{\\text{Vrai Positifs}}{\\text{Vrai Positifs} + \\text{Faux Négatifs}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import  recall_score\n\nrecall_per_class = recall_score(\n    data['true'], \n    data['pred'], \n    average=None,\n    labels=['chat', 'chien']\n)\nprint(\"Recall par classe (sklearn):\")\n\nRecall par classe (sklearn):\n\nprint(f\"Chat: {recall_per_class[0]:.3f}\")\n\nChat: 0.840\n\nprint(f\"Chien: {recall_per_class[1]:.3f}\")\n\nChien: 0.860\n\n# Recall moyen\nrecall_avg = recall_score(\n    data['true'], \n    data['pred'], \n    average='macro'\n)\nprint(f\"Recall moyen: {recall_avg:.3f}\")\n\nRecall moyen: 0.850\n\n\n\n\n\nconf_matrix &lt;- table(Prédit = data$pred, Réel = data$true)\nrecall_chat &lt;- conf_matrix[\"chat\",\"chat\"] / sum(conf_matrix[\"chat\",])\nrecall_chien &lt;- conf_matrix[\"chien\",\"chien\"] / sum(conf_matrix[\"chien\",])\n\nprint(\"\\nRecall par classe (manuel):\")\n\n[1] \"\\nRecall par classe (manuel):\"\n\nprint(paste(\"Chat:\", round(recall_chat, 3)))\n\n[1] \"Chat: 0.83\"\n\nprint(paste(\"Chien:\", round(recall_chien, 3)))\n\n[1] \"Chien: 0.872\"\n\n# Recall moyen\nrecall_moy &lt;- mean(c(recall_chat, recall_chien))\nprint(paste(\"Recall moyen:\", round(recall_moy, 3)))\n\n[1] \"Recall moyen: 0.851\"\n\n\n\n\n\n\n\nF1-Score\nLe F1-Score est la moyenne harmonique entre la précision et le recall, offrant ainsi un compromis entre les deux. C’est une mesure utile quand il faut équilibrer la précision et le recall\n\nAvantages : Prend en compte à la fois les faux positifs et les faux négatifs. Utile pour les problèmes avec des classes déséquilibrées.\nInconvénients : Si l’un des deux (précision ou recall) est faible, l’F1-score sera également faible.\n\n\\[\n\\text{F1-Score} = 2 \\times\\frac{\\text{Précision} \\times \\text{Recall}}{\\text{Précision} + \\text{Recall}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import f1_score\n\n# F1-score par classe\nf1_per_class = f1_score(\n    data['true'], \n    data['pred'], \n    average=None, \n    labels=['chat', 'chien']\n)\nprint(\"F1-Score par classe (sklearn):\")\n\nF1-Score par classe (sklearn):\n\nprint(f\"Chat: {f1_per_class[0]:.3f}\")\n\nChat: 0.848\n\nprint(f\"Chien: {f1_per_class[1]:.3f}\")\n\nChien: 0.851\n\n# F1-score moyen\nf1_avg = f1_score(\n    data['true'], \n    data['pred'], \n    average='macro'\n)\nprint(f\"F1-Score moyen: {f1_avg:.3f}\")\n\nF1-Score moyen: 0.850\n\n\n\n\n\nprecision_chat &lt;- conf_matrix[\"chat\", \"chat\"] / sum(conf_matrix[, \"chat\"])\nrecall_chat &lt;- conf_matrix[\"chat\", \"chat\"] / sum(conf_matrix[\"chat\", ])\nf1_chat &lt;- 2 * (precision_chat * recall_chat) / (precision_chat + recall_chat)\n\nprecision_chien &lt;- conf_matrix[\"chien\", \"chien\"] / sum(conf_matrix[, \"chien\"])\nrecall_chien &lt;- conf_matrix[\"chien\", \"chien\"] / sum(conf_matrix[\"chien\", ])\nf1_chien &lt;- 2 * (precision_chien * recall_chien) / (precision_chien + recall_chien)\n\nprint(\"\\nF1-Score par classe (manuel):\")\n\n[1] \"\\nF1-Score par classe (manuel):\"\n\nprint(paste(\"Chat:\", round(f1_chat, 3)))\n\n[1] \"Chat: 0.854\"\n\nprint(paste(\"Chien:\", round(f1_chien, 3)))\n\n[1] \"Chien: 0.845\"\n\n# F1-score moyen\nf1_moy &lt;- mean(c(f1_chat, f1_chien))\nprint(paste(\"F1-Score moyen:\", round(f1_moy, 3)))\n\n[1] \"F1-Score moyen: 0.85\"\n\n\n\n\n\n\n\nROC-AUC (Area Under the Curve)\nLa courbe ROC est utilisée pour visualiser la performance d’un modèle en fonction de ses seuils de classification. L’AUC mesure la capacité du modèle à distinguer entre les classes.\n\nAvantages : Fonctionne bien avec des classes déséquilibrées et permet une comparaison entre modèles avec des seuils différents.\nInconvénients : Peut être difficile à interpréter dans des contextes très spécifiques.\n\n\\[\nAUC = \\int_0^1 \\text{TPR}(fpr) \\, dfpr\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\nroc_auc = roc_auc_score(data['true'] == 'chien', data['probs'])\nprint(f\"ROC-AUC: {roc_auc:.3f}\")\n\nROC-AUC: 0.841\n\nfpr, tpr, thresholds = roc_curve(data['true'] == 'chien', data['probs'])\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--')\nplt.xlabel('Taux de Faux Positifs (FPR)')\nplt.ylabel('Taux de Vrais Positifs (TPR)')\nplt.title('Courbe ROC')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n\n\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nroc_auc &lt;- roc(data$true == \"chien\", data$probs)$auc\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\nprint(sprintf(\"ROC-AUC: %.3f\\n\", roc_auc))\n\n[1] \"ROC-AUC: 0.856\\n\"\n\nroc_curve &lt;- roc(data$true == \"chien\", data$probs)\n\nSetting levels: control = FALSE, case = TRUE\nSetting direction: controls &lt; cases\n\nplot(roc_curve, main = \"Courbe ROC\", col = \"blue\")\nlegend(\"bottomright\", legend = paste(\"AUC =\", round(roc_auc, 2)), col = \"blue\", lty = 1)\n\n\n\n\n\n\n\n\n\nLog Loss (Logarithmic Loss)\nLe Log-Loss mesure la performance d’un modèle en termes de probabilité. Plus il est bas, meilleure est la qualité des probabilités assignées par le modèle.\n\nAvantages : Prend en compte la confiance du modèle dans ses prédictions, ce qui est important pour évaluer les modèles qui prédisent des probabilités.\nInconvénients : Sensible aux prédictions incorrectes avec une forte confiance.\n\n\\[\n\\text{Log Loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import log_loss\n\nlog_loss_value = log_loss(data['true'], np.vstack([1 - data['probs'], data['probs']]).T, labels=['chat', 'chien'])\nprint(f\"Log-Loss: {log_loss_value:.3f}\")\n\nLog-Loss: 0.520\n\n\n\n\n\ndata$true_binary &lt;- ifelse(data$true == \"chien\", 1, 0)\n\nlog_loss &lt;- -mean(data$true_binary * log(data$probs) + (1 - data$true_binary) * log(1 - data$probs))\n\nprint(paste(\"Log Loss: \", round(log_loss, 4)))\n\n[1] \"Log Loss:  0.4953\"\n\n\n\n\n\n\n\nMatthews Correlation Coefficient (MCC)\nLe MCC mesure la corrélation entre les prédictions et les résultats réels, en prenant en compte les vrais positifs, faux positifs, vrais négatifs et faux négatifs. C’est une métrique particulièrement utile pour les classes déséquilibrées.\n\nAvantages : Représente un bon compromis global entre toutes les erreurs possibles (faux positifs, faux négatifs, vrais positifs, vrais négatifs).\nInconvénients : Plus difficile à interpréter que d’autres métriques comme l’accuracy ou le F1-score.\n\n\\[\nMCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import matthews_corrcoef\n\nmcc_value = matthews_corrcoef(data['true'], data['pred'])\nprint(f\"Matthews Correlation Coefficient (MCC): {mcc_value:.3f}\")\n\nMatthews Correlation Coefficient (MCC): 0.700\n\n\n\n\n\nlibrary(mltools)\nmcc_value &lt;- mcc(data$pred, data$true)\nprint(sprintf(\"Matthews Correlation Coefficient (MCC): %.3f\\n\", mcc_value))\n\n[1] \"Matthews Correlation Coefficient (MCC): 0.701\\n\""
  },
  {
    "objectID": "posts/2024-11-metrics-classification/es/index.html",
    "href": "posts/2024-11-metrics-classification/es/index.html",
    "title": "Métricas para la clasificación",
    "section": "",
    "text": "Buscamos identificar los resultados de un modelo que trata de diferenciar predicciones de perros y gatos. Para evaluar su rendimiento, se utilizan métricas adaptadas que permiten medir cuán preciso, confiable y equilibrado es el modelo en sus predicciones.\n\nPythonR\n\n\n\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 100\ndata = pd.DataFrame({\n    'true': ['perro'] * 50 + ['gato'] * 50,\n    'probs': np.concatenate([\n        np.random.uniform(0.5, 1, 50),  \n        np.random.uniform(0, 0.5, 50)   \n    ])\n})\n\ndata['pred'] = data['probs'].apply(lambda x: 'perro' if x &gt; 0.5 else 'gato')\n\nindices_erreurs = np.random.choice(n, 15, replace=False)\ndata.loc[indices_erreurs, 'probs'] = 1 - data.loc[indices_erreurs, 'probs']\ndata.loc[indices_erreurs, 'pred'] = data.loc[indices_erreurs, 'pred'].map({'perro': 'gato', 'gato': 'perro'})\n\n\n\n\nset.seed(123)\n\nn &lt;- 100\ndata &lt;- data.frame(\n  true = factor(c(rep(\"perro\", 50), rep(\"gato\", 50))),   \n  probs = c(runif(50, 0.5, 1), runif(50, 0, 0.5))        \n)\n\ndata$pred &lt;- factor(ifelse(data$probs &gt; 0.5, \"perro\", \"gato\"))\n\nindices_erreurs &lt;- sample(1:n, 15)   \ndata$probs[indices_erreurs] &lt;- 1 - data$probs[indices_erreurs]  \ndata$pred[indices_erreurs] &lt;- ifelse(data$pred[indices_erreurs] == \"perro\", \"gato\", \"perro\")"
  },
  {
    "objectID": "posts/2024-11-metrics-classification/es/index.html#ejemplo-de-datos",
    "href": "posts/2024-11-metrics-classification/es/index.html#ejemplo-de-datos",
    "title": "Métricas para la clasificación",
    "section": "",
    "text": "Buscamos identificar los resultados de un modelo que trata de diferenciar predicciones de perros y gatos. Para evaluar su rendimiento, se utilizan métricas adaptadas que permiten medir cuán preciso, confiable y equilibrado es el modelo en sus predicciones.\n\nPythonR\n\n\n\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(123)\n\nn = 100\ndata = pd.DataFrame({\n    'true': ['perro'] * 50 + ['gato'] * 50,\n    'probs': np.concatenate([\n        np.random.uniform(0.5, 1, 50),  \n        np.random.uniform(0, 0.5, 50)   \n    ])\n})\n\ndata['pred'] = data['probs'].apply(lambda x: 'perro' if x &gt; 0.5 else 'gato')\n\nindices_erreurs = np.random.choice(n, 15, replace=False)\ndata.loc[indices_erreurs, 'probs'] = 1 - data.loc[indices_erreurs, 'probs']\ndata.loc[indices_erreurs, 'pred'] = data.loc[indices_erreurs, 'pred'].map({'perro': 'gato', 'gato': 'perro'})\n\n\n\n\nset.seed(123)\n\nn &lt;- 100\ndata &lt;- data.frame(\n  true = factor(c(rep(\"perro\", 50), rep(\"gato\", 50))),   \n  probs = c(runif(50, 0.5, 1), runif(50, 0, 0.5))        \n)\n\ndata$pred &lt;- factor(ifelse(data$probs &gt; 0.5, \"perro\", \"gato\"))\n\nindices_erreurs &lt;- sample(1:n, 15)   \ndata$probs[indices_erreurs] &lt;- 1 - data$probs[indices_erreurs]  \ndata$pred[indices_erreurs] &lt;- ifelse(data$pred[indices_erreurs] == \"perro\", \"gato\", \"perro\")"
  },
  {
    "objectID": "posts/2024-11-metrics-classification/es/index.html#métricas",
    "href": "posts/2024-11-metrics-classification/es/index.html#métricas",
    "title": "Métricas para la clasificación",
    "section": "Métricas",
    "text": "Métricas\n\nMatriz de confusión\nLa matriz de confusión es una representación en tabla de las predicciones correctas e incorrectas:\n\\[\n\\begin{bmatrix}\nTP & FP \\\\\nFN & TN\n\\end{bmatrix}\n\\]\n\nTP (True Positives) : Número de predicciones correctas para la clase positiva.\nFP (False Positives) : Número de predicciones incorrectas para la clase positiva.\nFN (False Negatives) : Número de predicciones incorrectas para la clase negativa.\nTN (True Negatives) : Número de predicciones correctas para la clase negativa.\n\n\nPythonR\n\n\n\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nconf_matrix = confusion_matrix(data['true'], data['pred'])\nprint(\"Matrice de confusion Python:\")\n\nMatrice de confusion Python:\n\nprint(conf_matrix)\n\n[[42  8]\n [ 7 43]]\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, \n            annot=True, \n            fmt='d',\n            xticklabels=['gato', 'perro'],\n            yticklabels=['gato', 'perro'])\nplt.title('Matrice de confusion (Python)')\nplt.xlabel('Valeur réelle')\nplt.ylabel('Prédiction')\nplt.show()\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\nprint(\"Matrice de confusion R:\")\n\n[1] \"Matrice de confusion R:\"\n\ntable(Prédit = data$pred, Réel = data$true)\n\n       Réel\nPrédit gato perro\n  gato    44     9\n  perro    6    41\n\nconf_matrix_r &lt;- as.data.frame(table(data$pred, data$true))\nnames(conf_matrix_r) &lt;- c(\"Prediction\", \"Real\", \"Count\")\n\nggplot(conf_matrix_r, \n       aes(x = Real, y = Prediction, fill = Count)) +\n  geom_tile() +\n  geom_text(aes(label = Count)) +\n  scale_fill_gradient(low = \"white\", high = \"steelblue\") +\n  theme_minimal() +\n  labs(title = \"Matrice de confusion (R)\")\n\n\n\n\n\n\n\n\n\nExactitud (Accuracy)\nLa Exactitud mide la proporción de predicciones correctas entre el total de predicciones.\n\\[\n\\text{Exactitud} = \\frac{\\text{Verdaderos Positivos} + \\text{Verdaderos Negativos}}{\\text{Total}}\n\\]\n\nVentajas : Fácil de entender e interpretar. Representa bien el rendimiento general de un modelo cuando las clases están equilibradas.\nDesventajas : No tiene en cuenta el desequilibrio de clases. Un modelo puede tener una alta exactitud incluso si clasifica mal las clases minoritarias.\n\n\nPythonR\n\n\n\nfrom sklearn.metrics import  accuracy_score\nacc_sklearn = accuracy_score(data['true'], data['pred'])\nprint(f\"Accuracy (sklearn): {acc_sklearn:.3f}\")\n\nAccuracy (sklearn): 0.850\n\n\n\n\n\nacc_simple &lt;- mean(data$pred == data$true)\nprint(paste(\"Accuracy (simple):\", round(acc_simple, 3)))\n\n[1] \"Accuracy (simple): 0.85\"\n\n\n\n\n\n\n\nPrecisión\nLa precisión es la proporción de predicciones positivas correctas entre todas las predicciones positivas.\n\nVentajas : Útil cuando se quiere minimizar los falsos positivos. Por ejemplo, en escenarios donde una falsa alarma es costosa (como en la detección de fraudes).\nDesventajas : No tiene en cuenta los falsos negativos, lo que puede ser problemático en ciertos casos, como cuando se quiere evitar los falsos negativos.\n\n\\[\n\\text{Précision} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Positivos}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import  precision_score\n\nprecision_per_class = precision_score(\n    data['true'], \n    data['pred'], \n    average=None,\n    labels=['gato', 'perro']\n)\nprint(\"recisión por clase (sklearn):\")\n\nrecisión por clase (sklearn):\n\nprint(f\"gato: {precision_per_class[0]:.3f}\")\n\ngato: 0.857\n\nprint(f\"perro: {precision_per_class[1]:.3f}\")\n\nperro: 0.843\n\n# Précision moyenne\nprecision_avg = precision_score(\n    data['true'], \n    data['pred'], \n    average='macro'\n)\nprint(f\"Precisión promedio: {precision_avg:.3f}\")\n\nPrecisión promedio: 0.850\n\n\n\n\n\nconf_matrix &lt;- table(Prédit = data$pred, Réel = data$true)\nprecision_gato &lt;- conf_matrix[\"gato\",\"gato\"] / sum(conf_matrix[,\"gato\"])\nprecision_perro &lt;- conf_matrix[\"perro\",\"perro\"] / sum(conf_matrix[,\"perro\"])\n\nprint(\"\\nrecisión por clase (manuel):\")\n\n[1] \"\\nrecisión por clase (manuel):\"\n\nprint(paste(\"gato:\", round(precision_gato, 3)))\n\n[1] \"gato: 0.88\"\n\nprint(paste(\"perro:\", round(precision_perro, 3)))\n\n[1] \"perro: 0.82\"\n\nprecision_moy &lt;- mean(c(precision_gato, precision_perro))\nprint(paste(\"Precisión promedio:\", round(precision_moy, 3)))\n\n[1] \"Precisión promedio: 0.85\"\n\n\n\n\n\n\n\nRecall\nEl Recall mide la proporción de verdaderos positivos detectados entre todos los reales positivos. Es especialmente importante cuando se quiere minimizar los falsos negativos.\n\nVentajas : Útil en contextos donde es crucial capturar tantos casos positivos como sea posible (por ejemplo, en pruebas médicas).\nDesventajas : Ignora los falsos positivos, lo que puede llevar a un aumento de los falsos positivos en ciertos casos.\n\n\\[\n\\text{Recall} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import  recall_score\n\nrecall_per_class = recall_score(\n    data['true'], \n    data['pred'], \n    average=None,\n    labels=['gato', 'perro']\n)\nprint(\"Recall por classe (sklearn):\")\n\nRecall por classe (sklearn):\n\nprint(f\"gato: {recall_per_class[0]:.3f}\")\n\ngato: 0.840\n\nprint(f\"perro: {recall_per_class[1]:.3f}\")\n\nperro: 0.860\n\n# Recall moyen\nrecall_avg = recall_score(\n    data['true'], \n    data['pred'], \n    average='macro'\n)\nprint(f\"Recall promedio: {recall_avg:.3f}\")\n\nRecall promedio: 0.850\n\n\n\n\n\nconf_matrix &lt;- table(Prédit = data$pred, Réel = data$true)\nrecall_gato &lt;- conf_matrix[\"gato\",\"gato\"] / sum(conf_matrix[\"gato\",])\nrecall_perro &lt;- conf_matrix[\"perro\",\"perro\"] / sum(conf_matrix[\"perro\",])\n\nprint(\"\\nRecall par classe (manuel):\")\n\n[1] \"\\nRecall par classe (manuel):\"\n\nprint(paste(\"gato:\", round(recall_gato, 3)))\n\n[1] \"gato: 0.83\"\n\nprint(paste(\"perro:\", round(recall_perro, 3)))\n\n[1] \"perro: 0.872\"\n\n# Recall moyen\nrecall_moy &lt;- mean(c(recall_gato, recall_perro))\nprint(paste(\"Recall promedio:\", round(recall_moy, 3)))\n\n[1] \"Recall promedio: 0.851\"\n\n\n\n\n\n\n\nF1-Score\nEl F1-Score es una medida combinada de la precisión y el recall (recuperación). Es la media armónica de ambas, y es útil cuando se desea equilibrar estas dos métricas. El F1-Score es especialmente útil cuando hay un desbalance entre las clases.\n\nVentajas : Toma en cuenta tanto los falsos positivos (FP) como los falsos negativos (FN), lo que lo hace útil en problemas con clases desbalanceadas.\nDesventajas : Si la precisión o el recall son bajos, el F1-Score también será bajo.\n\n\\[\n\\text{F1-Score} = 2 \\times\\frac{\\text{Précision} \\times \\text{Recall}}{\\text{Précision} + \\text{Recall}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import f1_score\n\n# F1-score par classe\nf1_per_class = f1_score(\n    data['true'], \n    data['pred'], \n    average=None, \n    labels=['gato', 'perro']\n)\nprint(\"F1-Score par classe (sklearn):\")\n\nF1-Score par classe (sklearn):\n\nprint(f\"gato: {f1_per_class[0]:.3f}\")\n\ngato: 0.848\n\nprint(f\"perro: {f1_per_class[1]:.3f}\")\n\nperro: 0.851\n\n# F1-score moyen\nf1_avg = f1_score(\n    data['true'], \n    data['pred'], \n    average='macro'\n)\nprint(f\"F1-Score promedio: {f1_avg:.3f}\")\n\nF1-Score promedio: 0.850\n\n\n\n\n\nprecision_gato &lt;- conf_matrix[\"gato\", \"gato\"] / sum(conf_matrix[, \"gato\"])\nrecall_gato &lt;- conf_matrix[\"gato\", \"gato\"] / sum(conf_matrix[\"gato\", ])\nf1_gato &lt;- 2 * (precision_gato * recall_gato) / (precision_gato + recall_gato)\n\nprecision_perro &lt;- conf_matrix[\"perro\", \"perro\"] / sum(conf_matrix[, \"perro\"])\nrecall_perro &lt;- conf_matrix[\"perro\", \"perro\"] / sum(conf_matrix[\"perro\", ])\nf1_perro &lt;- 2 * (precision_perro * recall_perro) / (precision_perro + recall_perro)\n\nprint(\"\\nF1-Score par classe (manuel):\")\n\n[1] \"\\nF1-Score par classe (manuel):\"\n\nprint(paste(\"gato:\", round(f1_gato, 3)))\n\n[1] \"gato: 0.854\"\n\nprint(paste(\"perro:\", round(f1_perro, 3)))\n\n[1] \"perro: 0.845\"\n\n# F1-score moyen\nf1_moy &lt;- mean(c(f1_gato, f1_perro))\nprint(paste(\"F1-Score moyen:\", round(f1_moy, 3)))\n\n[1] \"F1-Score moyen: 0.85\"\n\n\n\n\n\n\n\nROC-AUC (Area Under the Curve)\nLa curva ROC muestra la relación entre la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR). El AUC (Área Bajo la Curva) mide la capacidad del modelo para diferenciar entre las clases.\n\nVentajas : Es eficaz para evaluar modelos con clases desbalanceadas, y permite comparar modelos con diferentes umbrales de clasificación.\nDesventajas : A veces es difícil de interpretar en contextos muy específicos.\n\n\\[\nAUC = \\int_0^1 \\text{TPR}(fpr) \\, dfpr\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\nroc_auc = roc_auc_score(data['true'] == 'perro', data['probs'])\nprint(f\"ROC-AUC: {roc_auc:.3f}\")\n\nROC-AUC: 0.841\n\nfpr, tpr, thresholds = roc_curve(data['true'] == 'perro', data['probs'])\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', label=f'Curva ROC (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', linestyle='--')\nplt.xlabel('Tasa de Falsos Positivos (FPR)')\nplt.ylabel('Tasa de Verdaderos Positivos (TPR)')\nplt.title('Courbe ROC')\nplt.legend(loc='lower right')\nplt.show()\n\n\n\n\n\n\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nroc_auc &lt;- roc(data$true == \"perro\", data$probs)$auc\n\nSetting levels: control = FALSE, case = TRUE\n\n\nSetting direction: controls &lt; cases\n\nprint(sprintf(\"ROC-AUC: %.3f\\n\", roc_auc))\n\n[1] \"ROC-AUC: 0.856\\n\"\n\nroc_curve &lt;- roc(data$true == \"perro\", data$probs)\n\nSetting levels: control = FALSE, case = TRUE\nSetting direction: controls &lt; cases\n\nplot(roc_curve, main = \"Courbe ROC\", col = \"blue\")\nlegend(\"bottomright\", legend = paste(\"AUC =\", round(roc_auc, 2)), col = \"blue\", lty = 1)\n\n\n\n\n\n\n\n\n\nLog Loss (Logarithmic Loss)\nEl Log-Loss mide la calidad de las probabilidades asignadas por un modelo. Un valor de Log-Loss más bajo indica que el modelo asigna probabilidades más precisas.\n\nVentajas : Evalúa la confianza del modelo en sus predicciones, lo cual es importante para modelos que predicen probabilidades.\nDesventajas : Es sensible a las predicciones incorrectas con alta confianza.\n\n\\[\n\\text{Log Loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import log_loss\n\nlog_loss_value = log_loss(data['true'], np.vstack([1 - data['probs'], data['probs']]).T, labels=['gato', 'perro'])\nprint(f\"Log-Loss: {log_loss_value:.3f}\")\n\nLog-Loss: 0.520\n\n\n\n\n\ndata$true_binary &lt;- ifelse(data$true == \"perro\", 1, 0)\n\nlog_loss &lt;- -mean(data$true_binary * log(data$probs) + (1 - data$true_binary) * log(1 - data$probs))\n\nprint(paste(\"Log Loss: \", round(log_loss, 4)))\n\n[1] \"Log Loss:  0.4953\"\n\n\n\n\n\n\n\nMatthews Correlation Coefficient (MCC)\nEl MCC mide la correlación entre las predicciones y los resultados reales, considerando los verdaderos positivos (TP), los falsos positivos (FP), los verdaderos negativos (TN) y los falsos negativos (FN). Es especialmente útil cuando las clases están desbalanceadas.\n\nVentajas : Proporciona un buen equilibrio entre todos los posibles errores (falsos positivos, falsos negativos, verdaderos positivos y verdaderos negativos).\nDesventajas : Es más difícil de interpretar que métricas como la precisión o el F1-Score.\n\n\\[\nMCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}\n\\]\n\nPythonR\n\n\n\nfrom sklearn.metrics import matthews_corrcoef\n\nmcc_value = matthews_corrcoef(data['true'], data['pred'])\nprint(f\"Matthews Correlation Coefficient (MCC): {mcc_value:.3f}\")\n\nMatthews Correlation Coefficient (MCC): 0.700\n\n\n\n\n\nlibrary(mltools)\nmcc_value &lt;- mcc(data$pred, data$true)\nprint(sprintf(\"Matthews Correlation Coefficient (MCC): %.3f\\n\", mcc_value))\n\n[1] \"Matthews Correlation Coefficient (MCC): 0.701\\n\""
  },
  {
    "objectID": "posts/2024-11-Closeread Prize/en/index.html",
    "href": "posts/2024-11-Closeread Prize/en/index.html",
    "title": "Closeread Prize: Evolution of Javelin throw distances",
    "section": "",
    "text": "This article is written using the closeread library in R, designed to create scrollytelling story.\n\n\n\n\nThe javelin throw is one of those sports that feels almost mythical. Watching an athlete throwing a javelin like object across a field with raw power and flawless technique is mesmerizing. And when it comes to records in this event, they’re nothing short of legendary. The men’s world record, held by Jan Železný since 1996 at an astounding 98.48 meters.\n\n\n\n\nWhile the current women’s world record was set by Barbora Špotáková in 2008, with a stunning throw of 72.28 meters.Theses marks seem almost untouchable, raising the question: Is there even room to go further ?\n\n\n\n\nWhat does it really take to break a javelin throw record? Is it all about raw strength and skill, or do things like biomechanics, equipment, and weather play a part too? And, are we nearing the limits of what the human body can achieve?\n\n\n\n\n(P.S. Here’s a pic of me throwing, I’m getting closer!)"
  },
  {
    "objectID": "posts/2024-11-Closeread Prize/en/index.html#women-performances",
    "href": "posts/2024-11-Closeread Prize/en/index.html#women-performances",
    "title": "Closeread Prize: Evolution of Javelin throw distances",
    "section": "Women performances",
    "text": "Women performances"
  },
  {
    "objectID": "posts/2024-11-Closeread Prize/en/index.html#men-performances",
    "href": "posts/2024-11-Closeread Prize/en/index.html#men-performances",
    "title": "Closeread Prize: Evolution of Javelin throw distances",
    "section": "Men performances",
    "text": "Men performances"
  }
]